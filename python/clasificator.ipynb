{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (images) shape: (60000, 28, 28)\n",
      "Training set (labels) shape: (60000,)\n",
      "Test set (images) shape: (10000, 28, 28)\n",
      "Test set (labels) shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set (images) shape: {shape}\".format(shape=x_train.shape))\n",
    "print(\"Training set (labels) shape: {shape}\".format(shape=y_train.shape))\n",
    "\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=x_test.shape))\n",
    "print(\"Test set (labels) shape: {shape}\".format(shape=y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'(Label: T-shirt/top)')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(x_train[0], (28,28))\n",
    "curr_lbl = np.argmax(y_train[0])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(x_train[1], (28,28))\n",
    "curr_lbl = np.argmax(y_train[1])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'one_hot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-c201fc6729cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'one_hot'"
     ]
    }
   ],
   "source": [
    " y_train.one_hot(y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=(10,) dtype=float32>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_1:0' shape=(10,) dtype=float32>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 200 \n",
    "learning_rate = 0.001 \n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data input (img shape: 28*28)\n",
    "n_input = 28\n",
    "\n",
    "# MNIST total classes (0-9 digits)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both placeholders are of type float\n",
    "x = tf.placeholder(\"float\", [None, 28,28,1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc2': tf.get_variable('W1', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc3': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wd1': tf.get_variable('W3', shape=(4*4*128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'out': tf.get_variable('W6', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc2': tf.get_variable('B1', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc3': tf.get_variable('B2', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bd1': tf.get_variable('B3', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out': tf.get_variable('B4', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):  \n",
    "\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = conv_net(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "#calculate accuracy across all the given images and average them out. \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    for i in range(training_iters):\n",
    "        for batch in range(len(train_X)//batch_size):\n",
    "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "            # Run optimization op (backprop).\n",
    "                # Calculate batch loss and accuracy\n",
    "            opt = sess.run(optimizer, feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calculate accuracy for all 10000 mnist test images\n",
    "        test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
    "        train_loss.append(loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
